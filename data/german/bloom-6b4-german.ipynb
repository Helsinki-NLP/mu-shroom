{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c91e75-4f4b-478e-8fdb-a94934c71de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "!export HF_HOME='./.hf'\n",
    "!export TRANSFORMERS_CACHE='./.hf'\n",
    "!export TRANSFORMERS_HOME='./.hf'\n",
    "!export HF_CACHE='./.hf'\n",
    "\n",
    "import os\n",
    "os.environ['HF_HOME'] = './.hf/'\n",
    "\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"questions-de.tsv\"\n",
    "records = pd.read_csv(file_path, sep='\\t').to_dict(orient='records')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de1f639-658f-46d1-8c91-99e25f6a71da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary Wikipedia URL</th>\n",
       "      <th>title</th>\n",
       "      <th>URL-de</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://en.wikipedia.org/wiki/David_F._Sandberg</td>\n",
       "      <td>David F. Sandberg</td>\n",
       "      <td>https://de.wikipedia.org/wiki/David_F._Sandberg</td>\n",
       "      <td>Welche Filme produzierte David Sandberg im Jah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Mouthier-Haute-P...</td>\n",
       "      <td>Mouthier-Haute-Pierre</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Mouthier-Haute-P...</td>\n",
       "      <td>Wann wurde das Benediktinerklosters Saint-Pier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Cilleruelo_de_Sa...</td>\n",
       "      <td>Cilleruelo de San Mamés</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Cilleruelo_de_Sa...</td>\n",
       "      <td>In welcher Provinz liegt die spanische Gemeind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Helsingin_Jalkap...</td>\n",
       "      <td>Helsingin Jalkapalloklubi</td>\n",
       "      <td>https://de.wikipedia.org/wiki/HJK_Helsinki</td>\n",
       "      <td>Zu welchem Verein wechselte Dawda Bah im Jahr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Gampel-Bratsch</td>\n",
       "      <td>Gampel-Bratsch</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Gampel-Bratsch</td>\n",
       "      <td>Welchen Presi gewann der Dokumentafilm \"Bratsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>https://zh.wikipedia.org/wiki/%E5%90%89%E5%88%...</td>\n",
       "      <td>吉列体育场</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Gillette_Stadium</td>\n",
       "      <td>Wie viele Zuschauer haben Platz im Gillette St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>https://fr.wikipedia.org/wiki/Oxycarenidae</td>\n",
       "      <td>Oxycarenidae</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Oxycarenidae</td>\n",
       "      <td>Wie viele Gattungen umfasst die Familie der Ox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>https://sv.wikipedia.org/wiki/Microsoft_Edge</td>\n",
       "      <td>Microsoft Edge</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Microsoft_Edge</td>\n",
       "      <td>Seit wann kann man Microsoft Edge auf iOS und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>https://en.wikipedia.org/wiki/Bombykol</td>\n",
       "      <td>Bombykol</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Bombykol</td>\n",
       "      <td>Wozu benutzen Insekten Bombykol?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>https://fr.wikipedia.org/wiki/Emden_(1925)</td>\n",
       "      <td>Emden (1925)</td>\n",
       "      <td>https://de.wikipedia.org/wiki/Emden_(Schiff,_1...</td>\n",
       "      <td>Wohin führte die 2. Reise des leichten Kreuzer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Primary Wikipedia URL  \\\n",
       "0      https://en.wikipedia.org/wiki/David_F._Sandberg   \n",
       "1    https://en.wikipedia.org/wiki/Mouthier-Haute-P...   \n",
       "2    https://en.wikipedia.org/wiki/Cilleruelo_de_Sa...   \n",
       "3    https://en.wikipedia.org/wiki/Helsingin_Jalkap...   \n",
       "4         https://en.wikipedia.org/wiki/Gampel-Bratsch   \n",
       "..                                                 ...   \n",
       "195  https://zh.wikipedia.org/wiki/%E5%90%89%E5%88%...   \n",
       "196         https://fr.wikipedia.org/wiki/Oxycarenidae   \n",
       "197       https://sv.wikipedia.org/wiki/Microsoft_Edge   \n",
       "198             https://en.wikipedia.org/wiki/Bombykol   \n",
       "199         https://fr.wikipedia.org/wiki/Emden_(1925)   \n",
       "\n",
       "                         title  \\\n",
       "0            David F. Sandberg   \n",
       "1        Mouthier-Haute-Pierre   \n",
       "2      Cilleruelo de San Mamés   \n",
       "3    Helsingin Jalkapalloklubi   \n",
       "4               Gampel-Bratsch   \n",
       "..                         ...   \n",
       "195                      吉列体育场   \n",
       "196               Oxycarenidae   \n",
       "197             Microsoft Edge   \n",
       "198                   Bombykol   \n",
       "199               Emden (1925)   \n",
       "\n",
       "                                                URL-de  \\\n",
       "0      https://de.wikipedia.org/wiki/David_F._Sandberg   \n",
       "1    https://de.wikipedia.org/wiki/Mouthier-Haute-P...   \n",
       "2    https://de.wikipedia.org/wiki/Cilleruelo_de_Sa...   \n",
       "3           https://de.wikipedia.org/wiki/HJK_Helsinki   \n",
       "4         https://de.wikipedia.org/wiki/Gampel-Bratsch   \n",
       "..                                                 ...   \n",
       "195     https://de.wikipedia.org/wiki/Gillette_Stadium   \n",
       "196         https://de.wikipedia.org/wiki/Oxycarenidae   \n",
       "197       https://de.wikipedia.org/wiki/Microsoft_Edge   \n",
       "198             https://de.wikipedia.org/wiki/Bombykol   \n",
       "199  https://de.wikipedia.org/wiki/Emden_(Schiff,_1...   \n",
       "\n",
       "                                              question  \n",
       "0    Welche Filme produzierte David Sandberg im Jah...  \n",
       "1    Wann wurde das Benediktinerklosters Saint-Pier...  \n",
       "2    In welcher Provinz liegt die spanische Gemeind...  \n",
       "3    Zu welchem Verein wechselte Dawda Bah im Jahr ...  \n",
       "4    Welchen Presi gewann der Dokumentafilm \"Bratsc...  \n",
       "..                                                 ...  \n",
       "195  Wie viele Zuschauer haben Platz im Gillette St...  \n",
       "196  Wie viele Gattungen umfasst die Familie der Ox...  \n",
       "197  Seit wann kann man Microsoft Edge auf iOS und ...  \n",
       "198                   Wozu benutzen Insekten Bombykol?  \n",
       "199  Wohin führte die 2. Reise des leichten Kreuzer...  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd67f30-c119-4f81-af69-3233ab48d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    ('k50_p0.90_t0.1', dict(top_k=50, top_p=0.90, temperature=0.1)),\n",
    "    ('k50_p0.95_t0.1', dict(top_k=50, top_p=0.95, temperature=0.1)),\n",
    "    ('k50_p0.90_t0.2', dict(top_k=50, top_p=0.90, temperature=0.2)),\n",
    "    ('k50_p0.95_t0.2', dict(top_k=50, top_p=0.95, temperature=0.2)),\n",
    "    ('k50_p0.90_t0.3', dict(top_k=50, top_p=0.90, temperature=0.3)),\n",
    "    ('k50_p0.95_t0.3', dict(top_k=50, top_p=0.95, temperature=0.3)),\n",
    "    ('k75_p0.90_t0.1', dict(top_k=75, top_p=0.90, temperature=0.1)),\n",
    "    ('k75_p0.95_t0.1', dict(top_k=75, top_p=0.95, temperature=0.1)),\n",
    "    ('k75_p0.90_t0.2', dict(top_k=75, top_p=0.90, temperature=0.2)),\n",
    "    ('k75_p0.95_t0.2', dict(top_k=75, top_p=0.95, temperature=0.2)),\n",
    "    ('k75_p0.90_t0.3', dict(top_k=75, top_p=0.90, temperature=0.3)),\n",
    "    ('k75_p0.95_t0.3', dict(top_k=75, top_p=0.95, temperature=0.3)),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce677541-1e77-417a-aa5a-b87f058d927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4fdff228b94b3398e63d2a887d8b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name = 'togethercomputer/Pythia-Chat-Base-7B' \n",
    "model_name = 'malteos/bloom-6b4-clp-german-oasst-v0.1' \n",
    "\n",
    "configs = [\n",
    "    ('k50_p0.90_t0.1', dict(top_k=50, top_p=0.90, temperature=0.1)),\n",
    "    ('k50_p0.95_t0.1', dict(top_k=50, top_p=0.95, temperature=0.1)),\n",
    "    ('k50_p0.90_t0.2', dict(top_k=50, top_p=0.90, temperature=0.2)),\n",
    "    ('k50_p0.95_t0.2', dict(top_k=50, top_p=0.95, temperature=0.2)),\n",
    "    ('k50_p0.90_t0.3', dict(top_k=50, top_p=0.90, temperature=0.3)),\n",
    "    ('k50_p0.95_t0.3', dict(top_k=50, top_p=0.95, temperature=0.3)),\n",
    "    ('k75_p0.90_t0.1', dict(top_k=75, top_p=0.90, temperature=0.1)),\n",
    "    ('k75_p0.95_t0.1', dict(top_k=75, top_p=0.95, temperature=0.1)),\n",
    "    ('k75_p0.90_t0.2', dict(top_k=75, top_p=0.90, temperature=0.2)),\n",
    "    ('k75_p0.95_t0.2', dict(top_k=75, top_p=0.95, temperature=0.2)),\n",
    "    ('k75_p0.90_t0.3', dict(top_k=75, top_p=0.90, temperature=0.3)),\n",
    "    ('k75_p0.95_t0.3', dict(top_k=75, top_p=0.95, temperature=0.3)),\n",
    "]\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe596b-067b-467f-a338-4b03b7cd2b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98b6a8f5425415fbae5af8edb576494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d455f90c25450dbeab507a0a4f3236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbe7452f1f84c3bb4d8f108b9666e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eadf9e290d48c98e75de6480dd5f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64230933a4f0488fb31a7a4926d4d545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b36ca432eb147bb97ed58d2b43ec5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9644d0e9f25340e3a6588b4dc0fd5296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a24370979e548e5a2f132afa238e459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f48254216664c46b8db19c93b01b8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36b8288ec154068906584fd57390f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6905d39535b4baca075bfe109e6ac29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29625f853064574a352847f1031b3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "from transformers.utils import logging\n",
    "import pathlib\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "for shorthand, config in tqdm.tqdm(configs):\n",
    "    output_file_path = f'german-{model_name.split(\"/\")[1]}.{shorthand}.jsonl'\n",
    "    anootation_file_path = f'german-{model_name.split(\"/\")[1]}-annotation.{shorthand}.jsonl'\n",
    "    if not pathlib.Path(anootation_file_path).is_file():\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "            for record in tqdm.tqdm(records):\n",
    "                message = record['question']\n",
    "                # prompt = f\"<human>: {message}\\n<bot>:\"\n",
    "                prompt = message + '\\n'\n",
    "                inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=512,\n",
    "                    num_return_sequences=1,\n",
    "                    no_repeat_ngram_size=2,\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_logits=True,\n",
    "                    do_sample=True,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                    # eos_token_id=tokenizer.encode('\\n'),\n",
    "                    # pad_token_id=tokenizer.encode('\\n')[0],\n",
    "                    **config,\n",
    "                )\n",
    "        \n",
    "                response_text = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "                response_text = response_text.replace(prompt, \"\") # response repeats the input in the begining\n",
    "                response_token_ids = outputs.sequences[0].to(\"cpu\").tolist()[len(inputs.input_ids[0]):]\n",
    "                # response_embeddings = outputs.sequences[0].to(\"cpu\").tolist()[len(inputs.input_ids[0]):]\n",
    "                response_tokens = tokenizer.convert_ids_to_tokens(response_token_ids)\n",
    "                response_logits = [l.to(\"cpu\").tolist() for l in outputs.logits]\n",
    "                \n",
    "                \"\"\"print(\"\\n\\n\")\n",
    "                print(f\"Q: {message}\")\n",
    "                print(f\"A: {response_text}\")\n",
    "        \n",
    "                print(\"input length\", len(inputs.input_ids[0]))\n",
    "                # print(\"sequence length\", len(outputs.sequences[0]))\n",
    "                print(\"response token length\", len(response_tokens))\n",
    "                print(\"response token ID length\", len(response_token_ids))\n",
    "                print(\"logits length\", len(response_logits))\n",
    "                # print(\"embedding length\", len(response_embeddings))\n",
    "                raise\"\"\"\n",
    "        \n",
    "        \n",
    "                record['model_id'] = model_name\n",
    "                record['lang'] = 'DE'\n",
    "        \n",
    "                record['output_text'] = response_text\n",
    "                record['output_tokens'] = response_tokens\n",
    "                record['output_logits'] = response_logits\n",
    "                # record['output_embeddings'] = response_embeddings\n",
    "        \n",
    "                json.dump(record, file, ensure_ascii=False)\n",
    "                file.write('\\n')\n",
    "        \n",
    "        columns_to_extract = ['URL-de', 'lang', 'question', 'model_id', 'output_text', 'output_tokens', 'title']\n",
    "        \n",
    "        output_data = []\n",
    "        \n",
    "        with open(anootation_file_path, 'w', encoding='utf-8') as file:\n",
    "            for data in records:\n",
    "                extracted_data = {key: data[key] for key in columns_to_extract if key in data}\n",
    "        \n",
    "                json.dump(extracted_data, file, ensure_ascii=False)\n",
    "                file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b01438b-5f9e-4b31-ad0b-afe54512203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56207813-c81c-4c89-a2f8-dbec95edb844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb451fa5f8384ae483f42135e2f744fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, MistralForCausalLM, set_seed\n",
    "model_name = \"occiglot/occiglot-7b-de-en-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = MistralForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a161bb8-3c10-41bf-9236-da8b4853a770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55843754f0244c75960943971dd78365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53a060b78d2416f9c8ba10778507705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0874dc7c3d3b400e9166c234f821c525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ba682c3bb14035a057b05dc28bcf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798689e3994c41ed9f32580d098138fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94672769a5fc43a3981d30259a6a2d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbe2997707f49d1a76c2894a556c38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74980d8aaa824afc84f28516e05ee50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad4969fc22e48d8a94e236de8d2c997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8938e1b2fbf84967824e825c49a17cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0c4869e5064a3aac927ddd8a7e375e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015eb258ac0b4481a99c85861d57295b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dbc5916b9b41d3b53333183eb57050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "from transformers.utils import logging\n",
    "import pathlib\n",
    "logging.set_verbosity_warning()\n",
    "#model = model.to(device)\n",
    "\n",
    "for shorthand, config in tqdm.tqdm(configs):\n",
    "    output_file_path = f'german-{model_name.split(\"/\")[1]}.{shorthand}.jsonl'\n",
    "    anootation_file_path = f'german-{model_name.split(\"/\")[1]}-annotation.{shorthand}.jsonl'\n",
    "    if not pathlib.Path(anootation_file_path).is_file():\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "            for record in tqdm.tqdm(records):\n",
    "                messages = [\n",
    "                   {\"role\": \"system\", 'content': 'You are a helpful assistant. Please give short and concise answers.'},\n",
    "                   {\"role\": \"user\", \"content\": record['question']},\n",
    "                ]\n",
    "                inputs = tokenizer.apply_chat_template(\n",
    "                    messages, \n",
    "                    tokenize=True, \n",
    "                    add_generation_prompt=True, \n",
    "                    return_dict=False, \n",
    "                    return_tensors='pt',\n",
    "                ).to(device)\n",
    "                outputs = model.generate(\n",
    "                    inputs,\n",
    "                    max_new_tokens=256,\n",
    "                    num_return_sequences=1,\n",
    "                    no_repeat_ngram_size=2,\n",
    "                    return_dict_in_generate=True,\n",
    "                    output_logits=True,\n",
    "                    do_sample=True,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                    # eos_token_id=tokenizer.encode('\\n'),\n",
    "                    # pad_token_id=tokenizer.encode('\\n')[0],\n",
    "                    **config,\n",
    "                )\n",
    "        \n",
    "                response_text = tokenizer.decode(outputs.sequences[0][len(inputs[0]):], skip_special_tokens=True)\n",
    "                # response_text = response_text.replace(prompt, \"\") # response repeats the input in the begining\n",
    "                response_token_ids = outputs.sequences[0].to(\"cpu\").tolist()[len(inputs[0]):]\n",
    "                # response_embeddings = outputs.sequences[0].to(\"cpu\").tolist()[len(inputs.input_ids[0]):]\n",
    "                response_tokens = tokenizer.convert_ids_to_tokens(response_token_ids)\n",
    "                response_logits = [l.to(\"cpu\").tolist() for l in outputs.logits]\n",
    "                \n",
    "                \"\"\"print(\"\\n\\n\")\n",
    "                print(f\"Q: {message}\")\n",
    "                print(f\"A: {response_text}\")\n",
    "        \n",
    "                print(\"input length\", len(inputs.input_ids[0]))\n",
    "                # print(\"sequence length\", len(outputs.sequences[0]))\n",
    "                print(\"response token length\", len(response_tokens))\n",
    "                print(\"response token ID length\", len(response_token_ids))\n",
    "                print(\"logits length\", len(response_logits))\n",
    "                # print(\"embedding length\", len(response_embeddings))\n",
    "                raise\"\"\"\n",
    "        \n",
    "        \n",
    "                record['model_id'] = model_name\n",
    "                record['lang'] = 'DE'\n",
    "        \n",
    "                record['output_text'] = response_text\n",
    "                record['output_tokens'] = response_tokens\n",
    "                record['output_logits'] = response_logits\n",
    "                # record['output_embeddings'] = response_embeddings\n",
    "        \n",
    "                json.dump(record, file, ensure_ascii=False)\n",
    "                file.write('\\n')\n",
    "        \n",
    "        columns_to_extract = ['URL-de', 'lang', 'question', 'model_id', 'output_text', 'output_tokens', 'title']\n",
    "        \n",
    "        output_data = []\n",
    "        \n",
    "        with open(anootation_file_path, 'w', encoding='utf-8') as file:\n",
    "            for data in records:\n",
    "                extracted_data = {key: data[key] for key in columns_to_extract if key in data}\n",
    "        \n",
    "                json.dump(extracted_data, file, ensure_ascii=False)\n",
    "                file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
